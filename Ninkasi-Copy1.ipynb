{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574aaef-dab4-4db1-8201-ed8646fee327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base system dependencies\n",
    "!sudo apt -y -qq install tesseract-ocr libtesseract-dev\n",
    "\n",
    "# required by PyPDF2 for page count and other pdf utilities\n",
    "!sudo apt-get -y -qq install poppler-utils python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcdab85-ef2d-4f3f-bd29-f075fb2204a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    USER = \"--user\"\n",
    "else:\n",
    "    USER = \"\"\n",
    "# Install Vertex AI LLM SDK, langchain and dependencies\n",
    "! pip install google-cloud-aiplatform langchain==0.0.229 chromadb==0.3.26 pydantic==1.10.8 typing-inspect==0.8.0 ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395dd12-5c86-4834-8029-91c61e9febd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import warnings\n",
    "from pathlib import Path as p\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1960c4-8e37-4e32-8cc0-73a91456b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_llm_text = VertexAI(model_name=\"text-bison@001\")\n",
    "vertex_embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf4f46-56e9-4624-bd02-48a66da5efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straight out of our docs and some online examples. Some examples cheated by reading the results immediately and dumping\n",
    "# it into some big string in the function but I'm not doing that\n",
    "#\n",
    "#\n",
    "def batch_process_documents(\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    gcs_input_uri: str,\n",
    "    gcs_output_uri: str,\n",
    "    processor_version_id: Optional[str] = None,\n",
    "    input_mime_type: Optional[str] = None,\n",
    "    field_mask: Optional[str] = None,\n",
    "    timeout: int = 9999, # gave it a loooong timeout because we are processing a lot of files\n",
    "):\n",
    "    # You must set the api_endpoint if you use a location other than \"us\".\n",
    "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    if not gcs_input_uri.endswith(\"/\") and \".\" in gcs_input_uri:\n",
    "        # Specify specific GCS URIs to process individual documents\n",
    "        gcs_document = documentai.GcsDocument(\n",
    "            gcs_uri=gcs_input_uri, mime_type=input_mime_type\n",
    "        )\n",
    "        # Load GCS Input URI into a List of document files\n",
    "        gcs_documents = documentai.GcsDocuments(documents=[gcs_document])\n",
    "        input_config = documentai.BatchDocumentsInputConfig(gcs_documents=gcs_documents)\n",
    "    else:\n",
    "        # Specify a GCS URI Prefix to process an entire directory\n",
    "        gcs_prefix = documentai.GcsPrefix(gcs_uri_prefix=gcs_input_uri)\n",
    "        input_config = documentai.BatchDocumentsInputConfig(gcs_prefix=gcs_prefix)\n",
    "        \n",
    "    # Cloud Storage URI for the Output Directory\n",
    "    gcs_output_config = documentai.DocumentOutputConfig.GcsOutputConfig(\n",
    "        gcs_uri=gcs_output_uri, field_mask=field_mask\n",
    "    )\n",
    "    # Where to write results\n",
    "    output_config = documentai.DocumentOutputConfig(gcs_output_config=gcs_output_config)\n",
    "\n",
    "    if processor_version_id:\n",
    "        # The full resource name of the processor version, e.g.:\n",
    "        # projects/{project_number}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}\n",
    "        name = client.processor_version_path(\n",
    "            project_number, location, processor_id, processor_version_id\n",
    "        )\n",
    "    else:\n",
    "        # The full resource name of the processor, e.g.:\n",
    "        # projects/{project_number}/locations/{location}/processors/{processor_id}\n",
    "        name = client.processor_path(project_number, location, processor_id)\n",
    "\n",
    "    request = documentai.BatchProcessRequest(\n",
    "        name=name,\n",
    "        input_documents=input_config,\n",
    "        document_output_config=output_config, \n",
    "    )\n",
    "\n",
    "    # BatchProcess returns a Long Running Operation (LRO)\n",
    "    operation = client.batch_process_documents(request)\n",
    "\n",
    "    # Continually polls the operation until it is complete.\n",
    "    # This could take some time for larger files\n",
    "    # Format: projects/{project_number}/locations/{location}/operations/{operation_id}\n",
    "    try:\n",
    "        print(f\"Waiting for operation {operation.operation.name} to complete...\")\n",
    "        operation.result(timeout=timeout)\n",
    "    # Catch exception when operation doesn\"t finish before timeout\n",
    "    except (RetryError, InternalServerError) as e:\n",
    "        print(e.message)\n",
    "\n",
    "    # NOTE: Can also use callbacks for asynchronous processing\n",
    "    #\n",
    "    # def my_callback(future):\n",
    "    #   result = future.result()\n",
    "    #\n",
    "    # operation.add_done_callback(my_callback)\n",
    "\n",
    "    # Once the operation is complete,\n",
    "    # get output document information from operation metadata\n",
    "    metadata = documentai.BatchProcessMetadata(operation.metadata)\n",
    "\n",
    "    if metadata.state != documentai.BatchProcessMetadata.State.SUCCEEDED:\n",
    "        raise ValueError(f\"Batch Process Failed: {metadata.state_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e55f2-a35f-4640-b94c-cd45ed182577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function\n",
    "batch_process_documents(\n",
    "        project_number=project_number,\n",
    "        location=location,\n",
    "        processor_id=processor_id,\n",
    "        gcs_input_uri=gcs_input_uri,\n",
    "        gcs_output_uri=gcs_output_uri,\n",
    "        input_mime_type=input_mime_type,\n",
    "        field_mask=field_mask,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d2f0f-b8f9-4b0c-bdbb-9f5a15cb6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the output files from DocAI from GCS. I'm using the document object from DocAI to easily load the JSON.\n",
    "#\n",
    "# Maybe its the old school metadata fanboy in me but I also store the all the paths as strings in the docs list\n",
    "#\n",
    "client = storage.Client()\n",
    "output_blobs = client.list_blobs(gcs_bucket_name, prefix=\"pdf_output/\")\n",
    "docs=[]\n",
    "paths=[]\n",
    "for blob in output_blobs:\n",
    "    if blob.content_type != \"application/json\":\n",
    "        print(f\"Skipping non-supported file: {blob.name} - Mimetype: {blob.content_type}\")\n",
    "        continue\n",
    "    paths.append(blob.name)\n",
    "    document=documentai.Document.from_json(blob.download_as_bytes(), ignore_unknown_fields=True)\n",
    "    docs.append(document.text)\n",
    "paths=\"\".join(paths)\n",
    "docs.append(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c35c8b-8183-49cf-841c-2f5b4a424899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The max token size for outputs from embeddings is 1024, same as the max input token size for Palm.\n",
    "# That leaves no room for a prompt, so I'm using the recursive textsplitter to make smaller chunks. \n",
    "# Might be interesting to see the results with even smaller chunks\n",
    "#\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=800, chunk_overlap=50)\n",
    "texts = text_splitter.create_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922c1b2-e36e-4ed0-873e-4c33fcef9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store docs in local vectorstore as index\n",
    "# it may take a while since API is rate limited\n",
    "# Also found this somewhere, added persistence for the db\n",
    "# This takes a lotta lottta lotta time\n",
    "db = Chroma.from_documents(texts, embeddings, persist_directory = \"index_ninkasi\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07a00a-ae7a-454b-a1b1-9110ed6546e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Maybe its the old school metadata fanboy in me but I also store the all the paths as strings in the docs list\n",
    "#\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "docs=[]\n",
    "list_dir = listdir(dir)\n",
    "for file_name in (list_dir):\n",
    "    full_path=dir+'/'+file_name\n",
    "    csv = CSVLoader (full_path).load()\n",
    "    for content in csv:\n",
    "        docs.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca331b3-4428-4a17-aa24-ae9fe731aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=800, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7c5c3-ad90-4d51-b3f9-ff216c5e4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store docs in local vectorstore as index\n",
    "# it may take a while since API is rate limited\n",
    "# Also found this somewhere, added persistence for the db\n",
    "# This takes a lotta lottta lotta time\n",
    "db = Chroma.from_documents(texts, embeddings, persist_directory = \"index_ninkasi\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71d50ff-8df9-453f-a5dd-3632cf042700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "dir='gcs/txt/'\n",
    "\n",
    "docs=[]\n",
    "list_dir = listdir(dir)\n",
    "for file_name in (list_dir):\n",
    "    full_path=dir+'/'+file_name\n",
    "    txt = TextLoader (full_path).load()\n",
    "    for content in txt:\n",
    "        docs.append(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf1268-f983-4644-bf77-aaed679b3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=800, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7019d0b-aceb-4024-9b5b-4d7365b6d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store docs in local vectorstore as index\n",
    "# it may take a while since API is rate limited\n",
    "# Also found this somewhere, added persistence for the db\n",
    "# This takes a lotta lottta lotta time\n",
    "db = Chroma.from_documents(texts, embeddings, persist_directory = \"index_ninkasi\")\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca23854-8666-47fd-914b-32d282810de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max k as a search arguments gives us some room to experiment what works best when using embeddings. \n",
    "#\n",
    "#\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89dceff-f916-4c39-b381-4bd1201e364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt_template = \"\"\"Use the context below create a recipe of max 1000 words with special ingredients for a beer with type below and translate into modern english:\n",
    "    Context: {context}\n",
    "    Type: {type}\n",
    "    recipe:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"type\"])\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fd651-0b18-4752-8954-a450255ddcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pgvector\n",
    "! pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5935219-6018-4511-a2ba-beb75fd8b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "user = \"postgres\"\n",
    "host = \"IP\"\n",
    "port = \"5432\"\n",
    "dbname= \"postgres\"\n",
    "password = \"Password\"\n",
    "\n",
    "\n",
    "CONNECTION_STRING = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}?sslmode=require\"\n",
    "\n",
    "COLLECTION_NAME = \"test\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=texts,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453506b9-c438-46e9-a4fe-0b1a3c989b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def generate_recipe(type):\n",
    "    docs = db.similarity_search(type, k=1)\n",
    "    inputs = [{\"context\": doc.page_content, \"type\": type} for doc in docs]\n",
    "    chain2= (chain.apply(inputs))\n",
    "    pprint.pprint(chain)\n",
    "    print(chain.apply(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3679bb-c0a8-4ae6-8401-ae081f0dff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_recipe('Summit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6aeae4-66ce-4512-9ac3-7a7e5e58313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.similarity_search_with(\"beer\", k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5bc0a-d545-407d-811e-87ef142afa47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
